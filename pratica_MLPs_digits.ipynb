{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucvseco/MLP_digits/blob/main/pratica_MLPs_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificando digítos com MLPs\n",
        "\n",
        "Vamos utilizar um modelo MLP para realizar a classificação de imagens que possuem digítos (0-9).\n",
        "\n",
        "Para o teste utilizaremos o dataset digits do sklearn (https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)\n",
        "\n",
        "O dataset é composto por imagens 8x8 em tons de cinza, cada uma com sua label correspondente (0-9).\n"
      ],
      "metadata": {
        "id": "3eOFRXwE0QKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 - Importando as bibliotecas e carregando o dataset\n",
        "\n",
        "Utilizamos o módulo datasets do sklearn para carregar os dados a partir da função load_digits(return_X_y=True).\n",
        "\n",
        "Passamos o parâmetro return_X_y com True para que a função retorne os exemplos e as anotações em variaveis separadas, atribuimos o resultado na variavel images e target, respectivamente. As variáveis serão retornadas como numpy.*ndarray*"
      ],
      "metadata": {
        "id": "Qs4SsGMJ0uEl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hUQvqij4z8bv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "images, target = datasets.load_digits(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## - Verificar as dimensões das variáveis images e target\n",
        "\n",
        "shape_images = images.shape\n",
        "shape_target = target.shape\n",
        "\n",
        "print(shape_images)\n",
        "print(shape_target)"
      ],
      "metadata": {
        "id": "4Mdn4OAU2n71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db2597a-ee1f-45ef-ca4f-c2371e56509d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n",
            "(1797,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## - Quantos exemplos possui o dataset digits?\n",
        "\n",
        "dataset_size = shape_images[0] + shape_target[0]\n",
        "\n",
        "print(dataset_size)"
      ],
      "metadata": {
        "id": "Kj_M9u8Z4FFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c91130-8f92-49ae-918b-2f548ea5e22f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 - Visualizando os exemplos\n",
        "\n",
        "Utilizando a biblioteca matplotlib, vamos tentar visualizar alguns dos dados disponíveis no dataset."
      ],
      "metadata": {
        "id": "1gN3gOdg4wER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, prediction in zip(axes, images, target):\n",
        "    ax.set_axis_off()\n",
        "    image = image.reshape(8, 8)\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(f\"Label: {prediction}\")"
      ],
      "metadata": {
        "id": "fUomUtW148xZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "09aa38cd-0ca4-4bc4-81d5-50713b427b4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 - Separando as partições\n",
        "\n",
        "Utilizaremos a função train_test_split do sklearn para separar as partições em dois conjuntos (treino e teste). Utilizaremos o conjunto de treino para ajustar o modelo e o conjunto de teste para avaliar o desempenho do nosso modelo.\n",
        "\n",
        "Utilizaremos a função de forma que o conjunto de treino possua 70% dos dados e o conjunto de teste possua 30%.\n",
        "\n",
        "Referência train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split"
      ],
      "metadata": {
        "id": "dey-3Riy5ZdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = None, None\n",
        "y_train, y_test = None, None\n",
        "\n",
        "# Utilize a função train_test_split para obter as partições\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, target, test_size=0.30, random_state=42)\n",
        "\n",
        "# Computa o tamanho de cada partição, atribuindo o valor nas variaveis abaixo\n",
        "train_size = X_train.shape[0] + y_train.shape[0]\n",
        "test_size  = X_test.shape[0] + y_test.shape[0]\n",
        "\n",
        "print(train_size, test_size)"
      ],
      "metadata": {
        "id": "DvJO41ta5_b_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec5bd61-394b-4b8a-a0d6-3115d4967783"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2514 1080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 - Inicializando e treinando o modelo\n",
        "\n",
        "Agora vamos carregar e treinar o modelo utilizando os dados da partição de treino.\n",
        "\n",
        "Vamos utilizar a classe MLPClassifier do sklearn para instanciar a nossa rede (https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
        "\n",
        "Criar um modelo que contenha 3 camadas escondidas de dimensão (50,20,10) utilizando a função de ativação relu, otimizador adam, e learning rate 0.001. (Utilize max_iter=300)"
      ],
      "metadata": {
        "id": "hu0FsBvX7k57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o modelo instanciando o classificador com o sklearn e atribua a variavel network\n",
        "\n",
        "network = MLPClassifier(hidden_layer_sizes=(50, 20, 10),\n",
        "                    activation='relu',\n",
        "                    solver='adam',\n",
        "                    learning_rate_init=0.001,\n",
        "                    max_iter=300,\n",
        "                    random_state=1)\n",
        "\n",
        "\n",
        "print(network.activation, network.solver,\n",
        "      network.learning_rate_init, network.hidden_layer_sizes)"
      ],
      "metadata": {
        "id": "QKhgcVs379tQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e865954-aacc-4566-c025-b2afd6fb6b4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu adam 0.001 (50, 20, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizar a função fit para realizar o treinamento com as partições X_train e y_train\n",
        "\n",
        "network.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8qwPS8sfac7E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "c3452b42-ec56-448e-ec11-fe803e1fc733"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300, random_state=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300, random_state=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 - Avaliando o resultado\n",
        "\n",
        "Utilizaremos a função predict, para realizar as predições com o conjunto X_test"
      ],
      "metadata": {
        "id": "AnqmJke3-0Sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 - Utilize a função predict a partir do modelo treinado\n",
        "\n",
        "predictions = network.predict(X_test)\n",
        "\n",
        "print(\n",
        "    f\"Classification report for classifier {network}:\\n\"\n",
        "    f\"{metrics.classification_report(y_test, predictions)}\\n\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZSZFppnR_PMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0479d140-5719-4273-9e14-95865b211f93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for classifier MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300, random_state=1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        53\n",
            "           1       1.00      0.92      0.96        50\n",
            "           2       0.98      1.00      0.99        47\n",
            "           3       0.96      0.96      0.96        54\n",
            "           4       0.98      1.00      0.99        60\n",
            "           5       0.97      0.94      0.95        66\n",
            "           6       0.98      0.98      0.98        53\n",
            "           7       0.96      0.98      0.97        55\n",
            "           8       0.89      0.98      0.93        43\n",
            "           9       0.98      0.95      0.97        59\n",
            "\n",
            "    accuracy                           0.97       540\n",
            "   macro avg       0.97      0.97      0.97       540\n",
            "weighted avg       0.97      0.97      0.97       540\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos verificar os parâmetros da rede a partir do atributo coefs_.\n",
        "Da mesma forma, podemos acessar o valor de bias de cada neurônio acessando o atributo intercepts_.\n",
        "\n",
        "Vamos acessar os atributos coefs_ e intercepts_ da rede para verificar a dimensão dos conjuntos de pesos da rede criada. Utilizaremos esses valores para calcular o numero de parâmetros treinaivéis que a nossa rede possui.\n"
      ],
      "metadata": {
        "id": "QSCIErIHB_-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = network.coefs_\n",
        "bias    = network.intercepts_\n",
        "\n",
        "# numero de parametros e substitua o valor da variável abaixo com o numero de parametros do modelo\n",
        "\n",
        "parameters_number = sum([w.size for w in weights]) + sum([b.size for b in bias])\n",
        "\n",
        "print(parameters_number)"
      ],
      "metadata": {
        "id": "bWGuZAF7AHf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb9273b-9819-48e3-aa13-92f9293201d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 - Testando em um dataset externo\n",
        "\n",
        "Treinamos e testamos nosso modelo em um unico dataset. Na prática, vamos querer aplicar o nosso modelo em diferentes conjuntos e dados.\n",
        "\n",
        "Para simular este caso, vamos carregar alguns imagens do dataset MNIST. Podemos acessar o MNIST pelo PyTorch, utlizando o módulo datasets.MNIST.\n",
        "\n",
        "O MNIST também é um dataset para classificação de digitos, porém, o dataset é composto por imagens em tons de cinza de dimensão 28x28 com anotações entre 0-9.\n",
        "\n",
        "As células seguintes são utilizadas para baixar a partição de teste do dataset localmente, carregar os exemplos utilizando a classe dataloader do PyTorch.\n",
        "\n",
        "Podemos manipular o dataloader como um objeto do tipo iterator, desta forma, podemos obter os exemplos utilizando a função next() do python; ou qualquer outra função compativel com iterators.\n",
        "\n",
        "Utilizamos o batch_size igual a 10, que significa que para cada iteração do dataloader obtemos 10 imagens do conjunto de teste.\n",
        "\n",
        "As imagens e labels são retornadas ao final do processo utilizando as variaveis mnist_images e mnist_label."
      ],
      "metadata": {
        "id": "-lGp8gW3IHnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "test_ds = datasets.MNIST(root = \".\", train = False,\n",
        "                         download = True, transform = transform)\n",
        "\n",
        "test_dl = data.DataLoader(\n",
        "    test_ds, batch_size=50, shuffle=True,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "mnist_test_images, mnist_test_labels = next(iter(test_dl))\n",
        "\n",
        "mnist_test_images  = mnist_test_images.numpy()\n",
        "mnist_test_labels  = mnist_test_labels.numpy()"
      ],
      "metadata": {
        "id": "VO7Ij0U3IMCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a88c6e8-cb4b-4f68-9d66-874e1d81cda7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 37564736.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 69618214.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 10885184.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12574606.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimindo a dimensão da imagem, podemos perceber que a representação utilizada pelo PyTorch não corresponde a utilizada pelo nosso modelo.\n",
        "\n",
        "O PyTorch representa os exemplos do mnist como (B, C, H, W), onde B é o tamanho do batch (numero de imagens), C o número de canais, H a altura da imagem e W a largura da imagem."
      ],
      "metadata": {
        "id": "oNAjrZv_MIHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mnist_test_images.shape)"
      ],
      "metadata": {
        "id": "X27nL-EsJJk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f082be63-b8d9-4b44-d36f-24c40a3e5633"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizar essa imagem no nosso modelo, precisamos redimensionar os dados para 8x8 (mesmo tamanho utilizado pela nossa rede). Em seguida, devemos converter essa entrada para um vetor de dimensão (B, 64), transformando nossa imagem 8x8 é um vetor unidimensional.\n"
      ],
      "metadata": {
        "id": "SyqcJjadMe7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squeezed_images = None\n",
        "\n",
        "# removendo a dimensão extra que representa os canais\n",
        "\n",
        "squeezed_images = np.squeeze(np.array(mnist_test_images))\n",
        "\n",
        "print(squeezed_images.shape)"
      ],
      "metadata": {
        "id": "GX1s2zMmMFz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af87c4c-4a03-4f2f-c936-8872430298ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resized_images = None\n",
        "\n",
        "# redimensionar as imagens para o tamanho 8x8\n",
        "\n",
        "resized_images = np.array([cv2.resize(img, (8, 8), interpolation=cv2.INTER_AREA) for img in squeezed_images])\n",
        "\n",
        "print(resized_images.shape)"
      ],
      "metadata": {
        "id": "e5joP8dePS6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9738a73c-aa55-4b12-c9e2-4b09e607814e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_transformed = None\n",
        "\n",
        "# transformar as imagens 8x8 em vetores de tamanho 64\n",
        "\n",
        "mnist_transformed = np.array([img.flatten() for img in resized_images])\n",
        "\n",
        "print(mnist_transformed.shape)"
      ],
      "metadata": {
        "id": "VnPr4hFDPyy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2016be3b-9077-4d53-ad6e-346eed5de066"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Vamos visualizar as imagens antes e depois das transformações"
      ],
      "metadata": {
        "id": "9Jrvw0WtRQIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando as imagens 28x28 antes da transformação\n",
        "\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, squeezed_images, mnist_test_labels):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "liZztWxDQ4bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "478114ac-ff4f-4cb3-d185-e94a706e6712"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando as imagens 8x8\n",
        "\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, mnist_transformed, mnist_test_labels):\n",
        "    ax.set_axis_off()\n",
        "    image = image.reshape(8, 8)\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "PmwydNYNLAKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "16ac5413-b3d3-4216-a27b-e332274fea19"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos passar agora nossas imagens transformadas para que o modelo realize as predições\n",
        "\n",
        "-> Utilizaremos a função predict para obter os resultados a partir da variavel network, utilizando como parametro nossa variavel mnist_transformed"
      ],
      "metadata": {
        "id": "sGKpkkP5RoTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#função predict a partir do modelo treinado\n",
        "\n",
        "predictions_mnist = network.predict(mnist_transformed)\n",
        "\n",
        "print(\n",
        "    f\"Classification report for classifier {network}:\\n\"\n",
        "    f\"{metrics.classification_report(mnist_test_labels, predictions_mnist)}\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "L7Nmvc4QRlhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb839847-cca7-47b1-a504-6fb54cbe49d9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for classifier MLPClassifier(hidden_layer_sizes=(50, 20, 10), max_iter=300, random_state=1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         6\n",
            "           1       0.18      0.40      0.25         5\n",
            "           2       0.00      0.00      0.00         4\n",
            "           3       0.00      0.00      0.00         4\n",
            "           4       0.10      0.50      0.16         4\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         5\n",
            "           7       1.00      0.20      0.33         5\n",
            "           8       0.27      0.38      0.32         8\n",
            "           9       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.16        50\n",
            "   macro avg       0.15      0.15      0.11        50\n",
            "weighted avg       0.17      0.16      0.12        50\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Avaliemos o resultado anterior. O modelo manteve a acurácia?\n",
        "\n",
        "A resposta é:\n",
        "Não"
      ],
      "metadata": {
        "id": "jG3N1o6tS6P0"
      }
    }
  ]
}